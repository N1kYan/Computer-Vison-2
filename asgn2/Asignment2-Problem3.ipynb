{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "using Optim\n",
    "using ImageFiltering\n",
    "using Interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convert_to_grayscale (generic function with 1 method)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert an Float32 rbg image to Float64 grayscale image\n",
    "function convert_to_grayscale(I::Array{Float32,3})\n",
    "    I=convert(Array{Float64,3}, I)\n",
    "    I_gray = 0.2989*I[:,:,1] + 0.5870*I[:,:,2] + 0.1140*I[:,:,3]\n",
    "    return I_gray::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_data (generic function with 1 method)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Tsukuba disparity dataset and convert it to grayscale\n",
    "function load_data()\n",
    "    i0_path = string(@__DIR__,\"/i0.png\")\n",
    "    i0 = imread(i0_path)\n",
    "    i0 = convert_to_grayscale(i0)\n",
    "    i1_path = string(@__DIR__,\"/i1.png\")\n",
    "    i1 = imread(i1_path)\n",
    "    i1 = convert_to_grayscale(i1)\n",
    "    gt_path = string(@__DIR__,\"/gt.png\")\n",
    "    gt64 = convert(Array{Float64,2}, imread(gt_path)*255)\n",
    "\n",
    "    @assert maximum(gt64) <= 16\n",
    "    return i0::Array{Float64,2}, i1::Array{Float64,2}, gt64::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_studentt (generic function with 1 method)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function log_studentt(x::Float64, alpha::Float64, sigma::Float64)\n",
    "    \n",
    "    #TODO: Change the code to accept matrix input\n",
    "    \n",
    "    function log_student(x, alpha, sigma)\n",
    "        return log((1.0 + (1.0/(2.0*sigma^2))*x^2)^(-1.0*alpha))\n",
    "    end\n",
    "    \n",
    "    function log_grad_student(x, alpha, sigma)\n",
    "        return -(2.0*alpha*x)/((2.0*sigma^2)+x^2)\n",
    "    end\n",
    "    \n",
    "    value = log_student(x, alpha, sigma)\n",
    "    grad = log_grad_student(x, alpha, sigma)\n",
    "\n",
    "    return value::Float64, grad::Float64\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stereo_log_prior (generic function with 1 method)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate stereo log prior.\n",
    "# Set: alpha=1.0, sigma=1.0\n",
    "function stereo_log_prior(x::Array{Float64,2})\n",
    "    alpha = 1.0\n",
    "    sigma = 1.0\n",
    "    \n",
    "    value = 0\n",
    "    grad = zeros(size(x))\n",
    "    for i = 1:size(x)[1]-1#Height?\n",
    "        for j = 1:size(x)[2]-1#Width?\n",
    "            value += log_studentt(x[i+1, j] - x[i,j], alpha, sigma)[1]\n",
    "            value += log_studentt(x[i, j+1] - x[i,j], alpha, sigma)[1]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Partial derivative to every pixel\n",
    "    for k = 1:size(x)[1]\n",
    "        for l = 1:size(x)[2]\n",
    "            if k + 1 <= size(x)[1]\n",
    "                grad[k,l] += log_studentt(x[k,l]-x[k+1,l], alpha, sigma)[2] \n",
    "            end\n",
    "            if k - 1 >= 1\n",
    "                grad[k,l] += log_studentt(x[k,l]-x[k-1,l], alpha, sigma)[2]\n",
    "            end\n",
    "            if l + 1 <= size(x)[2]\n",
    "                grad[k,l] += log_studentt(x[k,l]-x[k,l+1], alpha, sigma)[2]\n",
    "            end\n",
    "            if l - 1 >= 1\n",
    "                grad[k,l] += log_studentt(x[k,l]-x[k,l-1], alpha, sigma)[2]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return  value::Float64, grad::Array{Float64,2}\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stereo_log_likelihood (generic function with 1 method)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate stereo log likelihood.\n",
    "# Set: Alpha = 1.0, Sigma = 0.004\n",
    "function stereo_log_likelihood(x::Array{Float64,2}, im0::Array{Float64,2}, im1::Array{Float64,2})\n",
    "    alpha = 1.0\n",
    "    sigma = 0.004\n",
    "    value = 0\n",
    "    grad = zeros(size(im1))\n",
    "    \n",
    "    # We need the horizontal image derivative from I1 to calculate the gradient of the LH\n",
    "    kernel = centered([1.0 0.0 -1.0; 2.0 0.0 -2.0; 1.0 0.0 -1.0]);\n",
    "    sobel_x = imfilter(im1, kernel);\n",
    "    h_img_grad = imfilter(sobel_x, kernel')    \n",
    "    \n",
    "    # We need to interpolate im1 and the horizontal image derivative,\n",
    "    # as we use continous optimization and might have continous disparities now\n",
    "    im1 = interpolate(im1, BSpline(Linear()))\n",
    "    h_img_grad = interpolate(h_img_grad,  BSpline(Linear()))\n",
    "\n",
    "\n",
    "    for i = 1:size(x)[1]\n",
    "        for j = 1:size(x)[2]\n",
    "            # Clamp disparity values to (0, 14.0)\n",
    "            # TODO: Use bounded optimization instead\n",
    "            disp = clamp(x[i,j], 0.0, 14.0)\n",
    "            # Substract value of Im0 from value of (left) shifted Im1\n",
    "            d = im0[i,j]-im1[i-disp, j]\n",
    "            value += log_studentt(d, alpha, sigma)[1]\n",
    "            grad[i,j] = (-1)*log_studentt(d, alpha, sigma)[2]*h_img_grad[i-disp, j]          \n",
    "        end\n",
    "    end\n",
    "    return value::Float64, grad::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stereo_log_posterior (generic function with 1 method)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate stereo posterior\n",
    "function stereo_log_posterior(x::Array{Float64,2}, im0::Array{Float64,2}, im1::Array{Float64,2}) \n",
    "    #log(posterior) = log(prior*LH) = log(prior) + log(LH)\n",
    "    # (We can drop the marginalisation terms)\n",
    "    log_posterior = stereo_log_likelihood(x, im0, im1)[1] + stereo_log_prior(x)[1] #+ stereo_log_prior(im0)[1]\n",
    "    grad_lh = stereo_log_likelihood(x, im0, im1)[2]\n",
    "    grad_x = stereo_log_prior(x)[2]\n",
    "    # (Derivative of I0 to x should be zero, so we drop it ...)\n",
    "    log_posterior_grad = grad_lh + grad_x\n",
    "    \n",
    "    # Instead of maximizing the log (to 0), we want to minimize the - log (to 0)\n",
    "    return -log_posterior::Float64, -log_posterior_grad::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stereo (generic function with 1 method)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run stereo algorithm using gradient ascent or sth similar\n",
    "function stereo(x0::Array{Float64,2}, im0::Array{Float64,2}, im1::Array{Float64,2})\n",
    "   \n",
    "    # Helper function with fixed im0 and im1\n",
    "    function f(y)\n",
    "        value = stereo_log_posterior(y, im0, im1)[1]\n",
    "        return value\n",
    "    end\n",
    "    \n",
    "    # Helper function for gradients\n",
    "    function g!(storage, y)\n",
    "        grad = stereo_log_posterior(y, im0, im1)[2]\n",
    "        storage[:,:] = grad\n",
    "    end\n",
    "    \n",
    "    #=\n",
    "    \n",
    "    ---------- Boxed Optimization ----------\n",
    "    \n",
    "    # Minimum 0 disparity\n",
    "    lower = zeros(size(x0))\n",
    "\n",
    "    # Maximum 14.0 disparity\n",
    "    upper = fill(14.0, size(x0))\n",
    "\n",
    "    od = OnceDifferentiable(f, g!, x0)\n",
    "    \n",
    "    res = optimize(od, lower, upper, x0, Fminbox(GradientDescent()), options)\n",
    "    =#\n",
    "    \n",
    "    options = Optim.Options(iterations=10, show_trace=true, allow_f_increases=false)\n",
    "    # Specify optim algorithm here\n",
    "    res = optimize(f, g!, x0, ConjugateGradient(), options)\n",
    "    \n",
    "    x = Optim.minimizer(res)\n",
    "    return x::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "constant_disparity (generic function with 1 method)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create constant disparity of all 8's of size DISPARITY_SIZE\n",
    "function constant_disparity(disparity_size::Tuple{Int64,Int64})\n",
    "    disparity_map = fill(8.0, disparity_size)\n",
    "    return disparity_map::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "random_disparity (generic function with 1 method)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random disparity in [0,14] of size DISPARITY_SIZE\n",
    "# We changed DISPARITY_SIZE to a tuple of integers\n",
    "function random_disparity(disparity_size::Tuple{Int64,Int64})\n",
    "    disparity_map = Array{Float64,2}(rand(collect(1:14),disparity_size))\n",
    "    return disparity_map::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problem3 (generic function with 1 method)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function problem3()\n",
    "    # use problem 2's load_data\n",
    "    im0, im1, gt = load_data()\n",
    "    \n",
    "    # Display stereo: Initialized with constant 8's\n",
    "    const_d = constant_disparity(size(gt))\n",
    "    \n",
    "    # Display stereo: Initialized with noise in [0,14]\n",
    "    random_d = random_disparity(size(gt))\n",
    "    \n",
    "    # print(\"Prior GT disparity: \", stereo_log_prior(gt)[1])\n",
    "    # println(\"\\n Prior constant disparity: \", stereo_log_prior(const_d)[1])\n",
    "    # println(\"\\n Prior random disparity: \", stereo_log_prior(random_d)[1])\n",
    "    # print(\"\\nLH const disp: \", stereo_log_likelihood(const_d, im0, im1)[1])\n",
    "    x = stereo(random_d, im0, im1)\n",
    "    ## println(\"We got here\")\n",
    "    #figure()\n",
    "    #title(\"Estimated disparity map\")\n",
    "    #imshow(x, \"gray\")\n",
    "    #show()\n",
    "    #figure()\n",
    "    #title(\"Ground truth disparity map\")\n",
    "    #imshow(gt, \"gray\")\n",
    "    #show()\n",
    "    #imshow(shift_disparity(im0, gt), \"gray\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # print(\"\\nLH random disp: \", stereo_log_likelihood(random_d, im0, im1)[1])\n",
    "    \n",
    "    # Display stereo: Initialized with gt\n",
    "    # print(\"\\nLH GT disp: \", stereo_log_likelihood(gt, im0, im1)[1])\n",
    "    \n",
    "    # Coarse to fine estimation..\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(itp::AbstractInterpolation{T, N}, i::Vararg{Number, N}) where {T, N}` is deprecated, use `itp(i...)` instead.\n",
      "│   caller = stereo_log_likelihood(::Array{Float64,2}, ::Array{Float64,2}, ::Array{Float64,2}) at In[270]:26\n",
      "└ @ Main ./In[270]:26\n"
     ]
    },
    {
     "ename": "BoundsError",
     "evalue": "BoundsError: attempt to access 288×384 interpolate(::Array{Float64,2}, BSpline(Linear())) with element type Float64 at index [-11.0, 1]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 288×384 interpolate(::Array{Float64,2}, BSpline(Linear())) with element type Float64 at index [-11.0, 1]",
      "",
      "Stacktrace:",
      " [1] throw_boundserror(::Interpolations.BSplineInterpolation{Float64,2,Array{Float64,2},BSpline{Linear},Tuple{Base.OneTo{Int64},Base.OneTo{Int64}}}, ::Tuple{Float64,Int64}) at ./abstractarray.jl:484",
      " [2] BSplineInterpolation at /home/yannik/.julia/packages/Interpolations/jXoPW/src/b-splines/indexing.jl:6 [inlined]",
      " [3] getindex(::Interpolations.BSplineInterpolation{Float64,2,Array{Float64,2},BSpline{Linear},Tuple{Base.OneTo{Int64},Base.OneTo{Int64}}}, ::Float64, ::Int64) at ./deprecated.jl:57",
      " [4] stereo_log_likelihood(::Array{Float64,2}, ::Array{Float64,2}, ::Array{Float64,2}) at ./In[270]:26",
      " [5] stereo_log_posterior at ./In[271]:5 [inlined]",
      " [6] (::getfield(Main, Symbol(\"#g!#92\")){Array{Float64,2},Array{Float64,2}})(::Array{Float64,2}, ::Array{Float64,2}) at ./In[272]:12",
      " [7] (::getfield(NLSolversBase, Symbol(\"#fg!#8\")){getfield(Main, Symbol(\"#f#91\")){Array{Float64,2},Array{Float64,2}},getfield(Main, Symbol(\"#g!#92\")){Array{Float64,2},Array{Float64,2}}})(::Array{Float64,2}, ::Array{Float64,2}) at /home/yannik/.julia/packages/NLSolversBase/KG9Ie/src/objective_types/abstract.jl:13",
      " [8] value_gradient!!(::OnceDifferentiable{Float64,Array{Float64,2},Array{Float64,2}}, ::Array{Float64,2}) at /home/yannik/.julia/packages/NLSolversBase/KG9Ie/src/interface.jl:82",
      " [9] initial_state(::ConjugateGradient{Float64,Nothing,getfield(Optim, Symbol(\"##33#35\")),LineSearches.InitialHagerZhang{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}}}, ::Optim.Options{Float64,Nothing}, ::OnceDifferentiable{Float64,Array{Float64,2},Array{Float64,2}}, ::Array{Float64,2}) at /home/yannik/.julia/packages/Optim/Agd3B/src/multivariate/solvers/first_order/cg.jl:113",
      " [10] optimize at /home/yannik/.julia/packages/Optim/Agd3B/src/multivariate/optimize/optimize.jl:33 [inlined]",
      " [11] #optimize#88 at /home/yannik/.julia/packages/Optim/Agd3B/src/multivariate/optimize/interface.jl:123 [inlined]",
      " [12] optimize at /home/yannik/.julia/packages/Optim/Agd3B/src/multivariate/optimize/interface.jl:121 [inlined]",
      " [13] stereo at ./In[272]:33 [inlined]",
      " [14] problem3() at ./In[275]:15",
      " [15] top-level scope at In[276]:1"
     ]
    }
   ],
   "source": [
    "problem3()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
