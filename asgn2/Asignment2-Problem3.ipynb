{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convert_to_grayscale (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert an Float32 rbg image to Float64 grayscale image\n",
    "function convert_to_grayscale(I::Array{Float32,3})\n",
    "    I=convert(Array{Float64,3}, I)\n",
    "    I_gray = 0.2989*I[:,:,1] + 0.5870*I[:,:,2] + 0.1140*I[:,:,3]\n",
    "    return I_gray::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_data (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Tsukuba disparity dataset and convert it to grayscale\n",
    "function load_data()\n",
    "    i0_path = string(@__DIR__,\"/i0.png\")\n",
    "    i0 = imread(i0_path)\n",
    "    i0 = convert_to_grayscale(i0)\n",
    "    i1_path = string(@__DIR__,\"/i1.png\")\n",
    "    i1 = imread(i1_path)\n",
    "    i1 = convert_to_grayscale(i1)\n",
    "    gt_path = string(@__DIR__,\"/gt.png\")\n",
    "    gt64 = convert(Array{Float64,2}, imread(gt_path)*255)\n",
    "\n",
    "    @assert maximum(gt64) <= 16\n",
    "    return i0::Array{Float64,2}, i1::Array{Float64,2}, gt64::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_studentt (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function log_studentt(x::Float64, alpha::Float64, sigma::Float64)\n",
    "    \n",
    "    #TODO: Change the code to accept matrix input\n",
    "    \n",
    "    function log_student(x, alpha, sigma)\n",
    "        return log((1 + (1/(2*sigma^2))*x^2)^(-1*alpha))\n",
    "    end\n",
    "    \n",
    "    function log_grad_student(x, alpha, sigma)\n",
    "        return -(2*alpha*x)/((2*sigma^2)+2x^2)\n",
    "    end\n",
    "    \n",
    "    value = log_student(x, alpha, sigma)\n",
    "    grad = log_grad_student(x, alpha, sigma)\n",
    "\n",
    "    return value::Float64, grad::Float64\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stereo_log_prior (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate stereo log prior.\n",
    "# Set: alpha=1.0, sigma=1.0\n",
    "function stereo_log_prior(x::Array{Float64,2})\n",
    "    alpha = 1.0\n",
    "    sigma = 1.0\n",
    "    value = 0\n",
    "    grad = zeros(size(x))\n",
    "    # Vertical potential\n",
    "    for i = 1:size(x)[1]-1#Height?\n",
    "        for j = 1:size(x)[2]#Width?\n",
    "            value += log_studentt(x[i+1, j] - x[i,j], alpha, sigma)[1]\n",
    "        end\n",
    "    end \n",
    "    # Horizontal potential\n",
    "    for i = 1:size(x)[1]#Height?\n",
    "        for j = 1:size(x)[2]-1#Width?\n",
    "            value += log_studentt(x[i, j+1] - x[i,j], alpha, sigma)[1]\n",
    "        end\n",
    "    end\n",
    "    # Partial derivative to every pixel\n",
    "    for k = 1:size(x)[1]\n",
    "        for l = 1:size(x)[2]\n",
    "            if k + 1 <= size(x)[1]\n",
    "                grad[k,l] += log_studentt(x[k,l]-x[k+1,l], alpha, sigma)[2] \n",
    "            end\n",
    "            if k - 1 >= 1\n",
    "                grad[k,l] += log_studentt(x[k,l]-x[k-1,l], alpha, sigma)[2]\n",
    "            end\n",
    "            if l + 1 <= size(x)[2]\n",
    "                grad[k,l] += log_studentt(x[k,l]-x[k,l+1], alpha, sigma)[2]\n",
    "            end\n",
    "            if l - 1 >= 1\n",
    "                grad[k,l] += log_studentt(x[k,l]-x[k,l-1], alpha, sigma)[2]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return  value::Float64, grad::Array{Float64,2}\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_gradient (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculates the gradient of a given image in both directions\n",
    "function image_gradient(im::Array{Float64,2})\n",
    "    horizontal_im_grad = zeros(size(im))\n",
    "    vertical_im_grad = zeros(size(im))\n",
    "    for x = 1:size(im)[1]\n",
    "        for y = 1:size(im)[2]\n",
    "            if x-1 > 0\n",
    "                vertical_im_grad[x,y] -= im[x-1,y]\n",
    "            end\n",
    "            if x+1 < size(im)[1]\n",
    "                vertical_im_grad[x,y] += im[x+1,y]\n",
    "            end\n",
    "            if y-1 > 0\n",
    "                horizontal_im_grad[x,y] -= im[x,y-1]\n",
    "            end\n",
    "            if y+1 < size(im)[2]\n",
    "                horizontal_im_grad[x,y] += im[x,y+1]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return horizontal_im_grad::Array{Float64,2}, vertical_im_grad::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shift_disparity (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift all pixels of i1 to the right by the value of gt\n",
    "function shift_disparity(i1::Array{Float64,2}, gt::Array{Float64,2})\n",
    "    # TODO: do interpolation... constant disparity map\n",
    "    @assert size(i1) == size(gt)\n",
    "    id = zeros(size(i1))\n",
    "    for x = 1:size(i1)[2] \n",
    "        for y = 1:size(i1)[1]\n",
    "            #shifted_index = Int64(floor(x + gt[y,x]))\n",
    "            shifted_index = Int64(floor(clamp(x + gt[y,x],0.0, 360)))\n",
    "            if (shifted_index > 1) && (shifted_index < size(i1,2))\n",
    "                id[y, shifted_index] = i1[y,x]          \n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @assert size(id) == size(i1)\n",
    "    return id::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stereo_log_likelihood (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate stereo log likelihood.\n",
    "# Set: Alpha = 1.0, Sigma = 0.004\n",
    "function stereo_log_likelihood(x::Array{Float64,2}, im0::Array{Float64,2}, im1::Array{Float64,2})\n",
    "    alpha = 1.0\n",
    "    sigma = 0.004\n",
    "    value = 0\n",
    "    grad = zeros(size(im1))\n",
    "    # We can shift I1 by the disparity first\n",
    "    im1_d = shift_disparity(im1, x)\n",
    "    # We need the horizontal image derivative from I1 to calculate the gradient of the LH\n",
    "    h_img_grad = image_gradient(im1_d)[1]\n",
    "    for i = 1:size(x)[1]\n",
    "        for j = 1:size(x)[2]\n",
    "            d = im0[i,j]-im1_d[i, j]\n",
    "            value += log_studentt(d, alpha, sigma)[1]\n",
    "            grad[i,j] = (-1)*log_studentt(d, alpha, sigma)[2]*h_img_grad[i, j]          \n",
    "        end\n",
    "    end\n",
    "    return value::Float64, grad::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stereo_log_posterior (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate stereo posterior\n",
    "function stereo_log_posterior(x::Array{Float64,2}, im0::Array{Float64,2}, im1::Array{Float64,2}) \n",
    "    #log(posterior) = log(prior*LH) = log(prior) + log(LH)\n",
    "    # (We can drop the marginalisation terms)\n",
    "    log_posterior = stereo_log_likelihood(x, im0, im1)[1] + stereo_log_prior(x)[1] #+ stereo_log_prior(im0)[1]\n",
    "    grad_lh = stereo_log_likelihood(x, im0, im1)[2]\n",
    "    grad_x = stereo_log_prior(x)[2]\n",
    "    # (Derivative of I0 to x should be zero, so we drop it ...)\n",
    "    log_posterior_grad = grad_lh + grad_x\n",
    "    return log_posterior::Float64, log_posterior_grad::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stereo (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run stereo algorithm using gradient ascent or sth similar\n",
    "function stereo(x0::Array{Float64,2}, im0::Array{Float64,2}, im1::Array{Float64,2})\n",
    "    # Helper function with fixed im0 and im1\n",
    "    function f(y)\n",
    "        value = stereo_log_posterior(y, im0, im1)[1]\n",
    "        return value\n",
    "    end\n",
    "    function g!(storage, y)\n",
    "        grad = stereo_log_posterior(y, im0, im1)[2]\n",
    "        storage[:,:] = grad\n",
    "    end\n",
    "    options = Optim.Options(iterations=10, show_trace=true, allow_f_increases=true)\n",
    "    # Specify optim algorithm here\n",
    "    res = optimize(f, g!, x0, ConjugateGradient(), options)\n",
    "    x = Optim.maximizer(res)\n",
    "    return x::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "constant_disparity (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create constant disparity of all 8's of size DISPARITY_SIZE\n",
    "function constant_disparity(disparity_size::Tuple{Int64,Int64})\n",
    "    disparity_map = fill(8.0, disparity_size)\n",
    "    return disparity_map::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "random_disparity (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random disparity in [0,14] of size DISPARITY_SIZE\n",
    "# We changed DISPARITY_SIZE to a tuple of integers\n",
    "function random_disparity(disparity_size::Tuple{Int64,Int64})\n",
    "    disparity_map = Array{Float64,2}(rand(collect(1:14),disparity_size))\n",
    "    return disparity_map::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior GT disparity: -9595.86119620938\n",
      " Prior constant disparity: 0.0\n",
      "\n",
      " Prior random disparity: -472092.41558847844\n",
      "Iter     Function value   Gradient norm \n",
      "     0    -9.827913e+05     1.227502e+02\n",
      "     1    -1.003774e+06     1.238126e+02\n",
      "     2    -1.007346e+06     1.225802e+02\n",
      "     3    -1.009412e+06     1.229990e+02\n",
      "     4    -2.637350e+06     1.189384e+02\n",
      "     5    -2.640322e+06     1.189866e+02\n",
      "     6    -2.640526e+06     1.189842e+02\n",
      "     7    -2.640898e+06     1.189826e+02\n",
      "     8    -2.640896e+06     1.189825e+02\n",
      "     9    -2.670799e+06     1.217712e+02\n",
      "    10    -2.670797e+06     1.217710e+02\n"
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching MethodError()\nClosest candidates are:\n  MethodError(!Matched::Any, !Matched::Any) at boot.jl:298\n  MethodError(!Matched::Any, !Matched::Any, !Matched::UInt64) at boot.jl:295",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching MethodError()\nClosest candidates are:\n  MethodError(!Matched::Any, !Matched::Any) at boot.jl:298\n  MethodError(!Matched::Any, !Matched::Any, !Matched::UInt64) at boot.jl:295",
      "",
      "Stacktrace:",
      " [1] maximizer(::Optim.MultivariateOptimizationResults{ConjugateGradient{Float64,Nothing,getfield(Optim, Symbol(\"##33#35\")),LineSearches.InitialHagerZhang{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}}},Float64,Array{Float64,2},Float64,Float64,Array{OptimizationState{Float64,ConjugateGradient{Float64,Nothing,getfield(Optim, Symbol(\"##33#35\")),LineSearches.InitialHagerZhang{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}}}},1}}) at C:\\Users\\Marius\\.julia\\packages\\Optim\\Agd3B\\src\\maximize.jl:46",
      " [2] stereo(::Array{Float64,2}, ::Array{Float64,2}, ::Array{Float64,2}) at .\\In[19]:15",
      " [3] top-level scope at In[23]:14"
     ]
    }
   ],
   "source": [
    "#function problem3()\n",
    "    # use problem 2's load_data\n",
    "    im0, im1, gt = load_data()\n",
    "\n",
    "    # Display stereo: Initialized with constant 8's\n",
    "    const_d = constant_disparity(size(gt))\n",
    "    \n",
    "    # Display stereo: Initialized with noise in [0,14]\n",
    "    random_d = random_disparity(size(gt))\n",
    "    \n",
    "    print(\"Prior GT disparity: \", stereo_log_prior(gt)[1])\n",
    "    println(\"\\n Prior constant disparity: \", stereo_log_prior(const_d)[1])\n",
    "    println(\"\\n Prior random disparity: \", stereo_log_prior(random_d)[1])\n",
    "    # print(\"\\nLH const disp: \", stereo_log_likelihood(const_d, im0, im1)[1])\n",
    "    x = stereo(random_d, im0, im1)\n",
    "    println(\"We got here\")\n",
    "    #figure()\n",
    "    #title(\"Estimated disparity map\")\n",
    "    imshow(x, \"gray\")\n",
    "    show()\n",
    "    figure()\n",
    "    title(\"Ground truth disparity map\")\n",
    "    imshow(gt, \"gray\")\n",
    "    show()\n",
    "    \n",
    "    \n",
    "\n",
    "    # print(\"\\nLH random disp: \", stereo_log_likelihood(random_d, im0, im1)[1])\n",
    "    \n",
    "    # Display stereo: Initialized with gt\n",
    "    # print(\"\\nLH GT disp: \", stereo_log_likelihood(gt, im0, im1)[1])\n",
    "    \n",
    "    # Coarse to fine estimation..\n",
    "\n",
    "#end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior GT disparity: -9595.86119620938\n",
      " Prior constant disparity: 0.0\n",
      "\n",
      " Prior random disparity: -470664.20933544973\n",
      "Iter     Function value   Gradient norm \n",
      "     0    -9.803477e+05     1.240958e+02\n",
      "     1    -1.002183e+06     1.240280e+02\n",
      "     2    -1.007006e+06     1.242882e+02\n",
      "     3    -1.009331e+06     1.242676e+02\n",
      "     4    -2.730388e+06     1.163085e+02\n",
      "     5    -2.731832e+06     1.231989e+02\n",
      "     6    -2.732599e+06     1.231981e+02\n",
      "     7    -2.732760e+06     1.231977e+02\n",
      "     8    -2.764448e+06     1.180154e+02\n",
      "     9    -5.700691e+06     1.971937e+01\n",
      "    10    -5.701099e+06     1.971936e+01\n"
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching MethodError()\nClosest candidates are:\n  MethodError(!Matched::Any, !Matched::Any) at boot.jl:298\n  MethodError(!Matched::Any, !Matched::Any, !Matched::UInt64) at boot.jl:295",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching MethodError()\nClosest candidates are:\n  MethodError(!Matched::Any, !Matched::Any) at boot.jl:298\n  MethodError(!Matched::Any, !Matched::Any, !Matched::UInt64) at boot.jl:295",
      "",
      "Stacktrace:",
      " [1] maximizer(::Optim.MultivariateOptimizationResults{ConjugateGradient{Float64,Nothing,getfield(Optim, Symbol(\"##33#35\")),LineSearches.InitialHagerZhang{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}}},Float64,Array{Float64,2},Float64,Float64,Array{OptimizationState{Float64,ConjugateGradient{Float64,Nothing,getfield(Optim, Symbol(\"##33#35\")),LineSearches.InitialHagerZhang{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}}}},1}}) at C:\\Users\\Marius\\.julia\\packages\\Optim\\Agd3B\\src\\maximize.jl:46",
      " [2] stereo(::Array{Float64,2}, ::Array{Float64,2}, ::Array{Float64,2}) at .\\In[19]:15",
      " [3] problem3() at .\\In[17]:15",
      " [4] top-level scope at In[21]:1"
     ]
    }
   ],
   "source": [
    "problem3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
