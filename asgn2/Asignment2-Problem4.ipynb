{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convert_to_grayscale (generic function with 1 method)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert an Float32 rbg image to Float64 grayscale image\n",
    "function convert_to_grayscale(I::Array{Float32,3})\n",
    "    I=convert(Array{Float64,3}, I)\n",
    "    I_gray = 0.2989*I[:,:,1] + 0.5870*I[:,:,2] + 0.1140*I[:,:,3]\n",
    "    return I_gray::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_data (generic function with 1 method)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Tsukuba disparity dataset and convert it to grayscale\n",
    "function load_data()\n",
    "    i0_path = string(@__DIR__,\"/i0.png\")\n",
    "    i0 = imread(i0_path)\n",
    "    i0 = convert_to_grayscale(i0)\n",
    "    i1_path = string(@__DIR__,\"/i1.png\")\n",
    "    i1 = imread(i1_path)\n",
    "    i1 = convert_to_grayscale(i1)\n",
    "    gt_path = string(@__DIR__,\"/gt.png\")\n",
    "    gt64 = convert(Array{Float64,2}, imread(gt_path)*255)\n",
    "\n",
    "    @assert maximum(gt64) <= 16\n",
    "    return i0::Array{Float64,2}, i1::Array{Float64,2}, gt64::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "robust_func (generic function with 1 method)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Robust loss function returning function value and gradient\n",
    "function robust_func(x::Float64,alpha::Float64,c::Float64)\n",
    "    if alpha == 2.0\n",
    "        value = 0.5*(x/c)^2\n",
    "        gradient = x/(c^2)\n",
    "    elseif alpha == 0.0\n",
    "        value = log(0.5*(x/c)^2 + 1.0)\n",
    "        gradient = (2*x)/(x^2 + 2*c^2)\n",
    "    # TODO: case alpha == -inf ?\n",
    "    else\n",
    "        value = abs(alpha-2.0)/alpha * ((x/c)^2/abs(alpha-2) + 1.0)^(alpha/2) - 1.0\n",
    "        gradient = x/(c^2) * ((x/c)^2/abs(alpha-2.0) + 1.0)^(alpha/2 - 1)\n",
    "    end\n",
    "    # print(\"\\nValue of robust func: \", value)\n",
    "    return value::Float64, gradient::Float64\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prior (generic function with 1 method)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function prior(x::Array{Float64,2})\n",
    "    # TODO: Energy formularisation; Use sum instead of product!\n",
    "    alpha = 2.0\n",
    "    c = 1.0\n",
    "    prior = 0\n",
    "    grad_prior = zeros(size(x))\n",
    "    for i = 1:size(x)[1]-1\n",
    "        for j = 1:size(x)[2]-1\n",
    "            d1 = x[i,j]-x[i+1,j]\n",
    "            d2 = x[i,j]-x[i,j+1]\n",
    "            prior += robust_func(d1, alpha, c)[1] + robust_func(d2, alpha, c)[1]\n",
    "            grad = 0\n",
    "            if i+1 <= size(x)[1]\n",
    "                grad += robust_func(x[i,j]-x[i+1,j], alpha, c)[2]\n",
    "            end\n",
    "            if i-1 >= 1\n",
    "                grad += robust_func(x[i-1,j]-x[i,j], alpha, c)[2]\n",
    "            end\n",
    "            if j+1 <= size(x)[2]\n",
    "                grad += robust_func(x[i,j]-x[i,j+1], alpha, c)[2]\n",
    "            end\n",
    "            if j-1 >= 1\n",
    "                grad += robust_func(x[i,j-1]-x[i,j], alpha, c)[2]\n",
    "            end\n",
    "            grad_prior[i,j] = grad\n",
    "        end\n",
    "    end\n",
    "    # TODO: Normalization\n",
    "    return prior, grad_prior\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_gradient (generic function with 1 method)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculates the gradient of a given image in both directions\n",
    "function image_gradient(im::Array{Float64,2})\n",
    "    horizontal_im_grad = zeros(size(im))\n",
    "    vertical_im_grad = zeros(size(im))\n",
    "    for x = 1:size(im)[1]\n",
    "        for y = 1:size(im)[2]\n",
    "            if x-1 > 0\n",
    "                vertical_im_grad[x,y] -= im[x-1,y]\n",
    "            end\n",
    "            if x+1 < size(im)[1]\n",
    "                vertical_im_grad[x,y] += im[x+1,y]\n",
    "            end\n",
    "            if y-1 > 0\n",
    "                horizontal_im_grad[x,y] -= im[x,y-1]\n",
    "            end\n",
    "            if y+1 < size(im)[2]\n",
    "                horizontal_im_grad[x,y] += im[x,y+1]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return horizontal_im_grad::Array{Float64,2}, vertical_im_grad::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shift_disparity (generic function with 1 method)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift all pixels of i1 to the right by the value of gt\n",
    "function shift_disparity(i1::Array{Float64,2}, gt::Array{Float64,2})\n",
    "    # TODO: do interpolation... constant disparity map\n",
    "    @assert size(i1) == size(gt)\n",
    "    id = zeros(size(i1))\n",
    "    for x = 1:size(i1)[2] \n",
    "        for y = 1:size(i1)[1]\n",
    "            shifted_index = Int64(floor(x + gt[y,x]))\n",
    "            if (shifted_index > 1) && (shifted_index < size(i1,2))\n",
    "                id[y, shifted_index] = i1[y,x]          \n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @assert size(id) == size(i1)\n",
    "    return id::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "likelihood (generic function with 1 method)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function likelihood(x::Array{Float64, 2}, im0::Array{Float64, 2}, im1::Array{Float64, 2})\n",
    "    alpha = 0.0\n",
    "    c = 1.0\n",
    "    lh = 0\n",
    "    lh_grad = zeros(size(im1))\n",
    "    # We can shift I1 by the disparity first\n",
    "    im1_d = shift_disparity(im1, x)\n",
    "    # We need the horizontal image derivative from I1 to calculate the gradient of the LH\n",
    "    h_img_grad = image_gradient(im1_d)[1]\n",
    "    for i = 1:size(x)[1]\n",
    "        for j = 1:size(x)[2]\n",
    "            d = im0[i,j]-im1_d[i, j]\n",
    "            lh += robust_func(d, alpha, c)[1]\n",
    "            lh_grad[i,j] = (-1)*robust_func(d, alpha, c)[2]*h_img_grad[i, j]         \n",
    "        end\n",
    "    end\n",
    "    return lh::Float64, lh_grad::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "posterior (generic function with 1 method)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function posterior(x::Array{Float64, 2}, im0::Array{Float64, 2}, im1::Array{Float64, 2})\n",
    "    # (We can again drop the marginalisation terms)\n",
    "    post = likelihood(x, im0, im1)[1] + prior(x)[1] + prior(im0)[1]\n",
    "    grad_lh = likelihood(x, im0, im1)[2]\n",
    "    grad_x = prior(x)[2]\n",
    "    # (Derivative of I0 to x should be zero, so we drop it ...)\n",
    "    post_grad = grad_lh + grad_x\n",
    "    return post::Float64, post_grad::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stereo (generic function with 1 method)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function stereo(x0::Array{Float64, 2}, im0::Array{Float64, 2}, im1::Array{Float64, 2})\n",
    "    print(\"\\nRunning Stereo Algorithm...\")\n",
    "    # Helper function with fixed im0 and im1\n",
    "    function f(y)\n",
    "        value = -posterior(y, im0, im1)[1]\n",
    "        return value\n",
    "    end\n",
    "    function g!(storage, y)\n",
    "        grad = -posterior(y, im0, im1)[2]\n",
    "        storage[:,:] = grad\n",
    "    end\n",
    "    options = Optim.Options(iterations=200, show_trace=true, allow_f_increases=true)\n",
    "    # Specify optim algorithm here\n",
    "    res = optimize(f, g!, x0, GradientDescent(), options)\n",
    "    x = Optim.minimizer(res)\n",
    "    print(\"done!\")\n",
    "    return x::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "constant_disparity (generic function with 1 method)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create constant disparity of all 8's of size DISPARITY_SIZE\n",
    "function constant_disparity(disparity_size::Tuple{Int64,Int64})\n",
    "    disparity_map = fill(8.0, disparity_size)\n",
    "    return disparity_map::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "random_disparity (generic function with 1 method)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random disparity in [0,14] of size DISPARITY_SIZE\n",
    "# We changed DISPARITY_SIZE to a tuple of integers\n",
    "function random_disparity(disparity_size::Tuple{Int64,Int64})\n",
    "    disparity_map = Array{Float64,2}(rand(collect(1:14),disparity_size))\n",
    "    return disparity_map::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problem4 (generic function with 1 method)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function problem4()\n",
    "    #  Up to you...\n",
    "    im0, im1, gt = load_data()\n",
    "    print(\"Prior GT: \", prior(gt)[1])\n",
    "    \n",
    "     # Display stereo: Initialized with constant 8's\n",
    "    const_d = constant_disparity(size(gt))\n",
    "    print(\"\\nPrior constant disparity: \", prior(const_d)[1])\n",
    "    \n",
    "    # Display stereo: Initialized with noise in [0,14]\n",
    "    random_d = random_disparity(size(gt))\n",
    "    print(\"\\nPrior random disparity: \", prior(random_d)[1])\n",
    "    \n",
    "    # print(\"\\nLH const disp: \", stereo_log_likelihood(const_d, im0, im1)[1])\n",
    "    #x = stereo(random_d, im0, im1)\n",
    "    \n",
    "    # TODO: pyramid\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior GT: 9595.861196209407\n",
      "Prior constand disparity: 0.0\n",
      "Prior random disparity: 469524.6637403882"
     ]
    }
   ],
   "source": [
    "problem4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
