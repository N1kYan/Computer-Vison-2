{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convert_to_grayscale (generic function with 1 method)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert an Float32 rbg image to Float64 grayscale image\n",
    "function convert_to_grayscale(I::Array{Float32,3})\n",
    "    I=convert(Array{Float64,3}, I)\n",
    "    I_gray = 0.2989*I[:,:,1] + 0.5870*I[:,:,2] + 0.1140*I[:,:,3]\n",
    "    return I_gray::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_data (generic function with 1 method)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Tsukuba disparity dataset and convert it to grayscale\n",
    "function load_data()\n",
    "    i0_path = string(@__DIR__,\"/i0.png\")\n",
    "    i0 = imread(i0_path)\n",
    "    i0 = convert_to_grayscale(i0)\n",
    "    i1_path = string(@__DIR__,\"/i1.png\")\n",
    "    i1 = imread(i1_path)\n",
    "    i1 = convert_to_grayscale(i1)\n",
    "    gt_path = string(@__DIR__,\"/gt.png\")\n",
    "    gt64 = convert(Array{Float64,2}, imread(gt_path)*255)\n",
    "\n",
    "    @assert maximum(gt64) <= 16\n",
    "    return i0::Array{Float64,2}, i1::Array{Float64,2}, gt64::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "robust_func (generic function with 1 method)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Robust loss function returning function value and gradient\n",
    "function robust_func(x::Float64,alpha::Float64,c::Float64)\n",
    "    if alpha == 2.0\n",
    "        value = 0.5*(x/c)^2\n",
    "        gradient = x/(c^2)\n",
    "    elseif alpha == 0.0\n",
    "        value = log(0.5*(x/c)^2 + 1.0)\n",
    "        gradient = (2*x)/(x^2 + 2*c^2)\n",
    "    # TODO: case alpha == -inf ?\n",
    "    else\n",
    "        value = abs(alpha-2.0)/alpha * ((x/c)^2/abs(alpha-2) + 1.0)^(alpha/2) - 1.0\n",
    "        gradient = x/(c^2) * ((x/c)^2/abs(alpha-2.0) + 1.0)^(alpha/2 - 1)\n",
    "    end\n",
    "    # print(\"\\nValue of robust func: \", value)\n",
    "    return value::Float64, gradient::Float64\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prior (generic function with 1 method)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function prior(x::Array{Float64,2})\n",
    "    # TODO: Energy formularisation; Use sum instead of product!\n",
    "    alpha = 2.0\n",
    "    c = 1.0\n",
    "    prior = 0\n",
    "    grad_prior = zeros(size(x))\n",
    "    for i = 1:size(x)[1]-1\n",
    "        for j = 1:size(x)[2]-1\n",
    "            d1 = x[i,j]-x[i+1,j]\n",
    "            d2 = x[i,j]-x[i,j+1]\n",
    "            prior += robust_func(d1, alpha, c)[1] + robust_func(d2, alpha, c)[1]\n",
    "            grad = 0\n",
    "            if i+1 <= size(x)[1]\n",
    "                grad += robust_func(x[i,j]-x[i+1,j], alpha, c)[2]\n",
    "            end\n",
    "            if i-1 >= 1\n",
    "                grad += robust_func(x[i-1,j]-x[i,j], alpha, c)[2]\n",
    "            end\n",
    "            if j+1 <= size(x)[2]\n",
    "                grad += robust_func(x[i,j]-x[i,j+1], alpha, c)[2]\n",
    "            end\n",
    "            if j-1 >= 1\n",
    "                grad += robust_func(x[i,j-1]-x[i,j], alpha, c)[2]\n",
    "            end\n",
    "            grad_prior[i,j] = grad\n",
    "        end\n",
    "    end\n",
    "    # TODO: Normalization\n",
    "    return prior, grad_prior\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_gradient (generic function with 1 method)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculates the gradient of a given image in both directions\n",
    "function image_gradient(im::Array{Float64,2})\n",
    "    horizontal_im_grad = zeros(size(im))\n",
    "    vertical_im_grad = zeros(size(im))\n",
    "    for x = 1:size(im)[1]\n",
    "        for y = 1:size(im)[2]\n",
    "            if x-1 > 0\n",
    "                vertical_im_grad[x,y] -= im[x-1,y]\n",
    "            end\n",
    "            if x+1 < size(im)[1]\n",
    "                vertical_im_grad[x,y] += im[x+1,y]\n",
    "            end\n",
    "            if y-1 > 0\n",
    "                horizontal_im_grad[x,y] -= im[x,y-1]\n",
    "            end\n",
    "            if y+1 < size(im)[2]\n",
    "                horizontal_im_grad[x,y] += im[x,y+1]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return horizontal_im_grad::Array{Float64,2}, vertical_im_grad::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shift_disparity (generic function with 1 method)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift all pixels of i1 to the right by the value of gt\n",
    "function shift_disparity(i1::Array{Float64,2}, gt::Array{Float64,2})\n",
    "    # TODO: do interpolation... constant disparity map\n",
    "    @assert size(i1) == size(gt)\n",
    "    id = zeros(size(i1))\n",
    "    for x = 1:size(i1)[2] \n",
    "        for y = 1:size(i1)[1]\n",
    "            # shifted_index = Int64(floor(x + gt[y,x]))\n",
    "            shifted_index = Int64(floor(clamp(x + gt[y,x],0.0, 255.0)))\n",
    "            if (shifted_index > 1) && (shifted_index < size(i1,2))\n",
    "                id[y, shifted_index] = i1[y,x]          \n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @assert size(id) == size(i1)\n",
    "    return id::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "likelihood (generic function with 1 method)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function likelihood(x::Array{Float64, 2}, im0::Array{Float64, 2}, im1::Array{Float64, 2})\n",
    "    alpha = 0.0\n",
    "    c = 1.0\n",
    "    lh = 0\n",
    "    lh_grad = zeros(size(im1))\n",
    "    # We can shift I1 by the disparity first\n",
    "    im1_d = shift_disparity(im1, x)\n",
    "    # We need the horizontal image derivative from I1 to calculate the gradient of the LH\n",
    "    h_img_grad = image_gradient(im1_d)[1]\n",
    "    for i = 1:size(x)[1]\n",
    "        for j = 1:size(x)[2]\n",
    "            d = im0[i,j]-im1_d[i, j]\n",
    "            lh += robust_func(d, alpha, c)[1]\n",
    "            lh_grad[i,j] = (-1)*robust_func(d, alpha, c)[2]*h_img_grad[i, j]         \n",
    "        end\n",
    "    end\n",
    "    return lh::Float64, lh_grad::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "posterior (generic function with 1 method)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function posterior(x::Array{Float64, 2}, im0::Array{Float64, 2}, im1::Array{Float64, 2})\n",
    "    # (We can again drop the marginalisation terms)\n",
    "    post = likelihood(x, im0, im1)[1] + prior(x)[1] + prior(im0)[1]\n",
    "    grad_lh = likelihood(x, im0, im1)[2]\n",
    "    grad_x = prior(x)[2]\n",
    "    # (Derivative of I0 to x should be zero, so we drop it ...)\n",
    "    post_grad = grad_lh + grad_x\n",
    "    return post::Float64, post_grad::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stereo (generic function with 1 method)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function stereo(x0::Array{Float64, 2}, im0::Array{Float64, 2}, im1::Array{Float64, 2})\n",
    "    print(\"\\nRunning Stereo Algorithm...\")\n",
    "    # Helper function with fixed im0 and im1\n",
    "    function f(y)\n",
    "        value = -posterior(y, im0, im1)[1]\n",
    "        return value\n",
    "    end\n",
    "    function g!(storage, y)\n",
    "        grad = -posterior(y, im0, im1)[2]\n",
    "        storage[:,:] = grad\n",
    "    end\n",
    "    options = Optim.Options(iterations=200, show_trace=true, allow_f_increases=true)\n",
    "    # Specify optim algorithm here\n",
    "    res = optimize(f, g!, x0, ConjugateGradient(), options)\n",
    "    x = Optim.maximizer(res)\n",
    "    print(\"done!\")\n",
    "    return x::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "constant_disparity (generic function with 1 method)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create constant disparity of all 8's of size DISPARITY_SIZE\n",
    "function constant_disparity(disparity_size::Tuple{Int64,Int64})\n",
    "    disparity_map = fill(8.0, disparity_size)\n",
    "    return disparity_map::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "random_disparity (generic function with 1 method)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random disparity in [0,14] of size DISPARITY_SIZE\n",
    "# We changed DISPARITY_SIZE to a tuple of integers\n",
    "function random_disparity(disparity_size::Tuple{Int64,Int64})\n",
    "    disparity_map = Array{Float64,2}(rand(collect(1:14),disparity_size))\n",
    "    return disparity_map::Array{Float64,2}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problem4 (generic function with 1 method)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function problem4()\n",
    "    #  Up to you...\n",
    "    im0, im1, gt = load_data()\n",
    "    #print(\"Prior GT: \", prior(gt)[1])\n",
    "    \n",
    "     # Display stereo: Initialized with constant 8's\n",
    "    const_d = constant_disparity(size(gt))\n",
    "    #print(\"\\nPrior constant disparity: \", prior(const_d)[1])\n",
    "    \n",
    "    # Display stereo: Initialized with noise in [0,14]\n",
    "    random_d = random_disparity(size(gt))\n",
    "    #print(\"\\nPrior random disparity: \", prior(random_d)[1])\n",
    "    \n",
    "    # print(\"\\nLH const disp: \", stereo_log_likelihood(const_d, im0, im1)[1])\n",
    "    x = stereo(const_d, im0, im1)\n",
    "    imshow(x)\n",
    "    \n",
    "    # TODO: pyramid\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Stereo Algorithm...Iter     Function value   Gradient norm \n",
      "     0    -2.309055e+03     3.874187e-01\n",
      "     1    -4.329334e+06     2.686511e+02\n",
      "     2    -1.838070e+08     1.752539e+03\n",
      "     3    -7.934616e+08     3.641969e+03\n",
      "     4    -3.328513e+09     7.460678e+03\n",
      "     5    -1.334852e+10     1.494327e+04\n",
      "     6    -5.323462e+10     2.984705e+04\n",
      "     7    -2.136159e+11     5.979944e+04\n",
      "     8    -8.541591e+11     1.195983e+05\n",
      "     9    -3.417521e+12     2.392691e+05\n",
      "    10    -1.367480e+13     4.787039e+05\n",
      "    11    -5.467421e+13     9.573549e+05\n",
      "    12    -2.187295e+14     1.915185e+06\n",
      "    13    -8.748056e+14     3.830786e+06\n",
      "    14    -3.499130e+15     7.662796e+06\n",
      "    15    -1.399593e+16     1.532791e+07\n",
      "    16    -5.598080e+16     3.066032e+07\n",
      "    17    -2.239132e+17     6.132985e+07\n",
      "    18    -8.956122e+17     1.226780e+08\n",
      "    19    -3.582285e+18     2.453926e+08\n",
      "    20    -1.432848e+19     4.908583e+08\n",
      "    21    -5.731131e+19     9.818628e+08\n",
      "    22    -2.292348e+20     1.964018e+09\n",
      "    23    -9.168974e+20     3.928618e+09\n",
      "    24    -3.667423e+21     7.858403e+09\n",
      "    25    -1.466903e+22     1.571914e+10\n",
      "    26    -5.867345e+22     3.144293e+10\n",
      "    27    -2.346832e+23     6.289516e+10\n",
      "    28    -9.386903e+23     1.258089e+11\n",
      "    29    -3.754592e+24     2.516550e+11\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] likelihood(::Array{Float64,2}, ::Array{Float64,2}, ::Array{Float64,2}) at ./In[218]:17",
      " [2] posterior(::Array{Float64,2}, ::Array{Float64,2}, ::Array{Float64,2}) at ./In[219]:3",
      " [3] (::getfield(Main, Symbol(\"#f#33\")){Array{Float64,2},Array{Float64,2}})(::Array{Float64,2}) at ./In[220]:5",
      " [4] value!!(::OnceDifferentiable{Float64,Array{Float64,2},Array{Float64,2}}, ::Array{Float64,2}) at /home/yannik/.julia/packages/NLSolversBase/KG9Ie/src/interface.jl:9",
      " [5] value!(::OnceDifferentiable{Float64,Array{Float64,2},Array{Float64,2}}, ::Array{Float64,2}) at /home/yannik/.julia/packages/NLSolversBase/KG9Ie/src/interface.jl:28",
      " [6] value!(::Optim.ManifoldObjective{OnceDifferentiable{Float64,Array{Float64,2},Array{Float64,2}}}, ::Array{Float64,2}) at /home/yannik/.julia/packages/Optim/Agd3B/src/Manifolds.jl:31",
      " [7] (::getfield(LineSearches, Symbol(\"#Ï•#1\")){Optim.ManifoldObjective{OnceDifferentiable{Float64,Array{Float64,2},Array{Float64,2}}},Array{Float64,2},Array{Float64,2},Array{Float64,2}})(::Float64) at /home/yannik/.julia/packages/LineSearches/WrsMD/src/LineSearches.jl:25",
      " [8] _hzI12(::Float64, ::Optim.ManifoldObjective{OnceDifferentiable{Float64,Array{Float64,2},Array{Float64,2}}}, ::Array{Float64,2}, ::Array{Float64,2}, ::Array{Float64,2}, ::Float64, ::Float64, ::Float64, ::Float64, ::Float64, ::Float64, ::Bool, ::Bool, ::Base.RefValue{Bool}) at /home/yannik/.julia/packages/LineSearches/WrsMD/src/initialguess.jl:262",
      " [9] perform_linesearch!(::Optim.ConjugateGradientState{Array{Float64,2},Float64,Array{Float64,2}}, ::ConjugateGradient{Float64,Nothing,getfield(Optim, Symbol(\"##33#35\")),LineSearches.InitialHagerZhang{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}}}, ::Optim.ManifoldObjective{OnceDifferentiable{Float64,Array{Float64,2},Array{Float64,2}}}) at /home/yannik/.julia/packages/LineSearches/WrsMD/src/initialguess.jl:198",
      " [10] update_state!(::OnceDifferentiable{Float64,Array{Float64,2},Array{Float64,2}}, ::Optim.ConjugateGradientState{Array{Float64,2},Float64,Array{Float64,2}}, ::ConjugateGradient{Float64,Nothing,getfield(Optim, Symbol(\"##33#35\")),LineSearches.InitialHagerZhang{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}}}) at /home/yannik/.julia/packages/Optim/Agd3B/src/multivariate/solvers/first_order/cg.jl:155",
      " [11] optimize(::OnceDifferentiable{Float64,Array{Float64,2},Array{Float64,2}}, ::Array{Float64,2}, ::ConjugateGradient{Float64,Nothing,getfield(Optim, Symbol(\"##33#35\")),LineSearches.InitialHagerZhang{Float64},LineSearches.HagerZhang{Float64,Base.RefValue{Bool}}}, ::Optim.Options{Float64,Nothing}, ::Optim.ConjugateGradientState{Array{Float64,2},Float64,Array{Float64,2}}) at /home/yannik/.julia/packages/Optim/Agd3B/src/multivariate/optimize/optimize.jl:57",
      " [12] optimize at /home/yannik/.julia/packages/Optim/Agd3B/src/multivariate/optimize/optimize.jl:33 [inlined]",
      " [13] #optimize#88 at /home/yannik/.julia/packages/Optim/Agd3B/src/multivariate/optimize/interface.jl:123 [inlined]",
      " [14] optimize at /home/yannik/.julia/packages/Optim/Agd3B/src/multivariate/optimize/interface.jl:121 [inlined]",
      " [15] stereo(::Array{Float64,2}, ::Array{Float64,2}, ::Array{Float64,2}) at ./In[220]:14",
      " [16] problem4() at ./In[223]:15",
      " [17] top-level scope at In[224]:1"
     ]
    }
   ],
   "source": [
    "problem4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
