{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as tf\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import flow2rgb\n",
    "from utils import rgb2gray\n",
    "from utils import read_flo\n",
    "from utils import read_image\n",
    "\n",
    "from scipy.integrate import dblquad\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy2torch(array):\n",
    "    \"\"\" Converts 3D numpy HWC ndarray to 3D PyTorch CHW tensor.\"\"\"\n",
    "    assert (array.ndim == 3)\n",
    "\n",
    "    result = np.copy(array)\n",
    "    result = np.moveaxis(result,[1,2,0],[2,0,1])\n",
    "    result = torch.from_numpy(result)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch2numpy(tensor):\n",
    "    \"\"\" Convert 3D PyTorch CHW tensor to 3D numpy HWC ndarray.\"\"\"\n",
    "    assert (tensor.dim() == 3)\n",
    "\n",
    "    result = tensor.clone().permute(1,2,0).numpy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(im1_filename, im2_filename, flo_filename):\n",
    "    \"\"\" Loads images and flow ground truth. Returns 4D tensors.\"\"\"\n",
    "    i0_path = os.path.dirname(os.path.abspath(\"A3_P2\"))+\"/\"+im1_filename\n",
    "    i1_path = os.path.dirname(os.path.abspath(\"A3_P2\"))+\"/\"+im2_filename\n",
    "    flo_path = os.path.dirname(os.path.abspath(\"A3_P2\"))+\"/\"+flo_filename\n",
    "    i0 = read_image(i0_path)\n",
    "    i0 = rgb2gray(i0)\n",
    "    i1 = read_image(i1_path)\n",
    "    i1 = rgb2gray(i1)    \n",
    "    tensor1 = numpy2torch(i0).view(1,1,i0.shape[0],i0.shape[1])\n",
    "    tensor2 = numpy2torch(i1).view(1,1,i1.shape[0],i1.shape[1])\n",
    "    flow_gt = numpy2torch(read_flo(flo_path)).view(1,2,i1.shape[0],i1.shape[1])\n",
    "\n",
    "    return tensor1, tensor2, flow_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 388, 584])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i0,i1,flo=load_data(\"frame10.png\",\"frame11.png\",\"flow10.flo\")\n",
    "flo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_flow(flow, flow_gt):\n",
    "    \"\"\"\n",
    "    Evaluate the average endpoint error w.r.t the ground truth flow_gt.\n",
    "    Excludes pixels, where u or v components of flow_gt have values > 1e9.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert (flow.dim() == 4 and flow_gt.dim() == 4)\n",
    "    assert (flow.size(1) == 2 and flow_gt.size(1) == 2)\n",
    "\n",
    "    #u = flow[0,0,:,:] * flow[0,0,:,:].le(1e9).float()\n",
    "    #v = flow[0,1,:,:] * flow[0,1,:,:].le(1e9).float()\n",
    "    u = flow[0,0,:,:]\n",
    "    v = flow[0,0,:,:]\n",
    "    \n",
    "    # Filter for invalid pixels\n",
    "    u_gt = flow_gt[0,0,:,:] * flow_gt[0,0,:,:].le(1e9).float()\n",
    "    v_gt = flow_gt[0,1,:,:] * flow_gt[0,1,:,:].le(1e9).float()\n",
    "\n",
    "    # AEPE for each pixel\n",
    "    errors = np.sqrt((u-u_gt)**2 + (v-v_gt)**2)\n",
    "    \n",
    "    print(errors)\n",
    "    \n",
    "    # Average over all pixels\n",
    "    aepe = sum(sum(errors))/errors.nelement()\n",
    "\n",
    "    return aepe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(im, flow):\n",
    "    \"\"\" Warps given image according to the given optical flow.\"\"\"\n",
    "    assert (im.dim() == 4 and flow.dim() == 4)\n",
    "    assert (im.size(1) in [1,3] and flow.size(1) == 2)\n",
    "    \"\"\"\n",
    "    # Permute dimensions and range of flow for grid_sample()\n",
    "    flow = flow.permute(0,2,3,1)\n",
    "    flow[0,:,:,0] /= torch.max(flow[0,:,:,0])\n",
    "    flow[0,:,:,1] /= torch.max(flow[0,:,:,1])\n",
    "    \n",
    "    warped = torch.nn.functional.grid_sample(im,flow)\n",
    "    \"\"\"\n",
    "    norm_flow = torch.Tensor(flow.permute(0,2,3,1))\n",
    "    # You have to add the meshgrid according to this:\n",
    "    # https://discuss.pytorch.org/t/warp-video-frame-from-optical-flow/6013/4\n",
    "    W=norm_flow.size(1)\n",
    "    H=norm_flow.size(2)\n",
    "    \n",
    "    mesh= torch.meshgrid([torch.linspace(-1,1,H), torch.linspace(-1,1,W)])\n",
    "    print(\"flow shape\",norm_flow.shape, \"H\",H, \"W\",W)\n",
    "    print(\"mesh 0 shape\",mesh[0].shape)\n",
    "    print(\"mesh 1 shape\",mesh[1].shape)\n",
    "    norm_flow[:,:,:,:] = norm_flow[:,:,:,:] + mesh\n",
    "    norm_flow[:,:,:,1] = norm_flow[:,:,:,1] + meshW\n",
    "    \n",
    "    \n",
    "    norm_flow[:,:,:,0] = norm_flow[:,:,:,0] / (norm_flow.size(1)-1) # normalize it to (0,1)\n",
    "    norm_flow[:,:,:,1] = norm_flow[:,:,:,1] / (norm_flow.size(2)-1) # normalize it to (0,1)\n",
    "    norm_flow = norm_flow*2 - 1 # bringing it to the range (-1,1) for the grid_sample function\n",
    "    # interpolate the image with the flow\n",
    "    warped = tf.grid_sample(im, norm_flow)\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_warping_practice(im1, im2, flow_gt):\n",
    "    \"\"\" Visualizes the result of warping the second image by ground truth.\"\"\"\n",
    "    assert (im1.dim() == 4 and im2.dim() == 4 and flow_gt.dim() == 4)\n",
    "    assert (im1.size(1) in [1,3] and im2.size(1) in [1,3] and flow_gt.size(1) == 2)\n",
    "    \n",
    "    warped_im2 = warp_image(im2, flow_gt)\n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"Image 1\")\n",
    "    plt.imshow(im1[0,0,:,:], cmap=\"gray\")\n",
    "    plt.subplot(132)\n",
    "    plt.title(\"Warped Image 2\")\n",
    "    plt.imshow(warped_im2[0,0,:,:], cmap=\"gray\")\n",
    "    plt.subplot(133)\n",
    "    plt.title(\"Difference\")\n",
    "    plt.imshow(im1[0,0,:,:]-warped_im2[0,0,:,:], cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_hs(im1, im2, flow, lambda_hs):\n",
    "    \"\"\" Evalutes Horn-Schunck energy function.\"\"\"\n",
    "    assert (im1.dim() == 4 and im2.dim() == 4 and flow.dim() == 4)\n",
    "    assert (im1.size(1) == 1 and im2.size(1) == 1 and flow.size(1) == 2)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def grad_u(x,y): return np.gradient(flow[0,0,:,:])[x,y]\n",
    "    def grad_v(x,y): return np.gradient(flow[0,1,:,:])[x,y]\n",
    "    # TODO: Interpolate It1 and It0\n",
    "    def It1(x,y): return warp_image(im2,flow)[0,0,x,y]\n",
    "    def It0(x,y): return im1[0,0,x,y]\n",
    "\n",
    "    def integral(x,y):\n",
    "        return (It1(x,y)-It0(x,y))**2 + lambda_hs*(np.norm(grad_u)**2 + np.norm(grad_v)**2)\n",
    "    \n",
    "    energy = dblquad(integral, -np.inf, np.inf, -np.inf, np.inf)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using sum instead of integral (discrete pixels in picture)\n",
    "    It1 = warp_image(im2,flow)[0,0,:,:]\n",
    "    It0 = im1[0,0,:,:]\n",
    "    \n",
    "    # TODO: use sobelfilter on u(x,y) and v(x,y)\n",
    "    #sobel_filter = torch.tensor([[[[1., 2. , 1.], [0., 0., 0.], [-1., -2. , -1.]]]])\n",
    "    #f = sobel_filter.expand(1,1,3,3)\n",
    "    #grad_u = tf.conv2d(torch.unsqueeze(flow[0,0,:,:], 0), sobel_filter, padding=1)\n",
    "    #grad_v = tf.conv2d(torch.unsqueeze(flow[0,1,:,:], 0), sobel_filter, padding=1)\n",
    "    \n",
    "    sobel_filter_x = torch.autograd.Variable(torch.Tensor([[[[-1., 0. , 1.], [-2., 0., 2.], [-1., 0. , 1.]]]]))\n",
    "    sobel_filter_y = torch.autograd.Variable(torch.Tensor([[[[-1., -2., -1.], [0., 0., 0.], [1., 2., 1.]]]]))\n",
    "    u = torch.autograd.Variable(flow[:,0,:,:].unsqueeze(0))\n",
    "    v = torch.autograd.Variable(flow[:,1,:,:].unsqueeze(0))\n",
    "    du_dx = tf.conv2d(u, sobel_filter_x, padding=1)\n",
    "    du_dy = tf.conv2d(u, sobel_filter_y, padding=1)                                         \n",
    "    dv_dx = tf.conv2d(v, sobel_filter_x, padding=1)\n",
    "    dv_dy = tf.conv2d(v, sobel_filter_y, padding=1)\n",
    "                                             \n",
    "    energy = 0\n",
    "    for x in np.arange(0, np.shape(It1)[0]):\n",
    "        for y in np.arange(0, np.shape(It1)[1]):\n",
    "            energy += (It1[x,y]-It0[x,y])**2 \n",
    "            energy += lambda_hs*(norm([du_dx[0,0,x,y], du_dy[0,0,x,y]])**2 + norm([dv_dx[0,0,x,y], dv_dy[0,0,x,y]])**2)\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_flow(im1, im2, flow_gt, lambda_hs, learning_rate, num_iter):\n",
    "    \"\"\"\n",
    "    Estimate flow using HS with Gradient Descent.\n",
    "    Displays average endpoint error.\n",
    "    Visualizes flow field.\n",
    "\n",
    "    Returns estimated flow]\n",
    "    \"\"\"\n",
    "    assert (im1.dim() == 4 and im2.dim() == 4 and flow_gt.dim() == 4)\n",
    "    assert (im1.size(1) == 1 and im2.size(1) == 1 and flow_gt.size(1) == 2)\n",
    "\n",
    "    # Initial flow\n",
    "    flow = torch.randn(1,2,flow_gt.size(2),flow_gt.size(3),requires_grad=True)\n",
    "    \n",
    "    for i in np.arange(0, num_iter):\n",
    "        print(\"Iteration \", num_iter+1)\n",
    "        # Forward pass\n",
    "        # TODO: Warp im1 or im2??\n",
    "        im2_estimate = warp_image(im1,flow)\n",
    "        loss = energy_hs(im1, im2_estimate, flow, lambda_hs)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        update = flow.grad()\n",
    "        flow += learning_rate * update\n",
    "    \n",
    "    print(\"Gradient Descent AEPE: \", evaluate_flow(flow, flow_gt))\n",
    "    plt.figure()\n",
    "    plt.title(\"Flow estimated with gradient descent\")\n",
    "    plt.imshow(flow2rgb(flow))\n",
    "    plt.show()\n",
    "        \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_flow_LBFGS(im1, im2, flow_gt, lambda_hs, learning_rate, num_iter):\n",
    "    \"\"\"\n",
    "    Estimates flow using HS with LBFGS.\n",
    "    Displays average endpoint error.\n",
    "    Visualizes flow field.\n",
    "\n",
    "    Returns estimated flow\n",
    "    \"\"\"\n",
    "    assert (im1.dim() == 4 and im2.dim() == 4 and flow_gt.dim() == 4)\n",
    "    assert (im1.size(1) == 1 and im2.size(1) == 1 and flow_gt.size(1) == 2)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_flow_coarse_to_fine(im1, im2, flow_gt, lambda_hs, learning_rate,\n",
    "                                 num_iter, num_level):\n",
    "    \"\"\"\n",
    "    Estimates flow using HS with LBFGS in a coarse-to-fine scheme.\n",
    "    Displays average endpoint error.\n",
    "    Visualizes flow field.\n",
    "\n",
    "    Returns estimated flow\n",
    "    \"\"\"\n",
    "    assert (im1.dim() == 4 and im2.dim() == 4 and flow_gt.dim() == 4)\n",
    "    assert (im1.size(1) == 1 and im2.size(1) == 1 and flow_gt.size(1) == 2)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem2():\n",
    "    \n",
    "    \n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    # Loading data\n",
    "    im1, im2, flow_gt = load_data(\"frame10.png\", \"frame11.png\", \"flow10.flo\")\n",
    "\n",
    "\n",
    "    # Parameters\n",
    "    lambda_hs = 0.0015\n",
    "    num_iter = 400\n",
    "\n",
    "    # Warping_practice\n",
    "    visualize_warping_practice(im1, im2, flow_gt)\n",
    "    \"\"\"\n",
    "    print(\"HS: \", energy_hs(im1,im2,flow_gt,lambda_hs))\n",
    "    \n",
    "    # Gradient descent\n",
    "    learning_rate = 20\n",
    "    estimate_flow(im1, im2, flow_gt, lambda_hs, learning_rate, num_iter)\n",
    "\n",
    "    \n",
    "    # LBFGS\n",
    "    learning_rate = 1\n",
    "    estimate_flow_LBFGS(im1, im2, flow_gt, lambda_hs, learning_rate, num_iter)\n",
    "\n",
    "    # Coarse to fine\n",
    "    learning_rate = 1\n",
    "    num_level = 4\n",
    "    estimate_flow_coarse_to_fine(\n",
    "        im1, im2, flow_gt, lambda_hs, learning_rate, num_iter, num_level)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flow shape torch.Size([1, 388, 584, 2]) H 584 W 388\n",
      "mesh 0 shape torch.Size([584, 388])\n",
      "mesh 1 shape torch.Size([584, 388])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "add(): argument 'other' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-0d7845e41109>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mproblem2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-f0e5c32b7519>\u001b[0m in \u001b[0;36mproblem2\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Warping_practice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mvisualize_warping_practice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflow_gt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \"\"\"\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"HS: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menergy_hs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflow_gt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlambda_hs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-b084fc0c3f31>\u001b[0m in \u001b[0;36mvisualize_warping_practice\u001b[1;34m(im1, im2, flow_gt)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mim2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mflow_gt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mwarped_im2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwarp_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflow_gt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-5c7059b3a451>\u001b[0m in \u001b[0;36mwarp_image\u001b[1;34m(im, flow)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mesh 0 shape\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmesh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mesh 1 shape\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmesh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mnorm_flow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorm_flow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmesh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;31m#norm_flow[:,:,:,1] = norm_flow[:,:,:,1] + meshW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mnorm_flow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorm_flow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnorm_flow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# normalize it to (0,1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: add(): argument 'other' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "problem2()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
