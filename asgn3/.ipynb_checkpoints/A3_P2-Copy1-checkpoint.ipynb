{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as tf\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import flow2rgb\n",
    "from utils import rgb2gray\n",
    "from utils import read_flo\n",
    "from utils import read_image\n",
    "from torch.autograd import variable\n",
    "\n",
    "from scipy.integrate import dblquad\n",
    "from numpy.linalg import norm\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy2torch(array):\n",
    "    \"\"\" Converts 3D numpy HWC ndarray to 3D PyTorch CHW tensor.\"\"\"\n",
    "    assert (array.ndim == 3)\n",
    "\n",
    "    result = array\n",
    "    result = np.moveaxis(result,[1,2,0],[2,0,1])\n",
    "    result = torch.from_numpy(result)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch2numpy(tensor):\n",
    "    \"\"\" Convert 3D PyTorch CHW tensor to 3D numpy HWC ndarray.\"\"\"\n",
    "    assert (tensor.dim() == 3)\n",
    "\n",
    "    result = tensor.permute(1,2,0).numpy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(im1_filename, im2_filename, flo_filename):\n",
    "    \"\"\" Loads images and flow ground truth. Returns 4D tensors.\"\"\"\n",
    "    i0_path = os.path.dirname(os.path.abspath(\"A3_P2\"))+\"/\"+im1_filename\n",
    "    i1_path = os.path.dirname(os.path.abspath(\"A3_P2\"))+\"/\"+im2_filename\n",
    "    flo_path = os.path.dirname(os.path.abspath(\"A3_P2\"))+\"/\"+flo_filename\n",
    "    i0 = read_image(i0_path)\n",
    "    i0 = rgb2gray(i0)\n",
    "    i1 = read_image(i1_path)\n",
    "    i1 = rgb2gray(i1)    \n",
    "    tensor1 = numpy2torch(i0).view(1,1,i0.shape[0],i0.shape[1])\n",
    "    tensor2 = numpy2torch(i1).view(1,1,i1.shape[0],i1.shape[1])\n",
    "    flow_gt = numpy2torch(read_flo(flo_path)).view(1,2,i1.shape[0],i1.shape[1])\n",
    "\n",
    "    return tensor1, tensor2, flow_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_flow(flow, flow_gt):\n",
    "    \"\"\"\n",
    "    Evaluate the average endpoint error w.r.t the ground truth flow_gt.\n",
    "    Excludes pixels, where u or v components of flow_gt have values > 1e9.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert (flow.dim() == 4 and flow_gt.dim() == 4)\n",
    "    assert (flow.size(1) == 2 and flow_gt.size(1) == 2)\n",
    "\n",
    "    u = flow[0,0,:,:] * flow[0,0,:,:].le(1e9).float()\n",
    "    v = flow[0,1,:,:] * flow[0,1,:,:].le(1e9).float()\n",
    "    #u = flow[0,0,:,:]\n",
    "    #v = flow[0,1,:,:]\n",
    "    \n",
    "    # Filter for invalid pixels\n",
    "    u_gt = flow_gt[0,0,:,:] * flow_gt[0,0,:,:].le(1e9).float()\n",
    "    v_gt = flow_gt[0,1,:,:] * flow_gt[0,1,:,:].le(1e9).float()\n",
    "\n",
    "    # AEPE for each pixel\n",
    "    errors = np.sqrt((u-u_gt)**2 + (v-v_gt)**2)\n",
    "    \n",
    "    #print(errors)\n",
    "    \n",
    "    # Average over all pixels\n",
    "    aepe = sum(sum(errors))/errors.nelement()\n",
    "\n",
    "    return aepe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(im, flow):\n",
    "    \"\"\" Warps given image according to the given optical flow.\"\"\"\n",
    "    assert (im.dim() == 4 and flow.dim() == 4)\n",
    "    assert (im.size(1) in [1,3] and flow.size(1) == 2)\n",
    "    \"\"\"\n",
    "    # Permute dimensions and range of flow for grid_sample()\n",
    "    flow = flow.permute(0,2,3,1)\n",
    "    flow[0,:,:,0] /= torch.max(flow[0,:,:,0])\n",
    "    flow[0,:,:,1] /= torch.max(flow[0,:,:,1])\n",
    "    \n",
    "    warped = torch.nn.functional.grid_sample(im,flow)\n",
    "    \"\"\"\n",
    "    norm_flow = torch.Tensor(flow.permute(0,2,3,1))\n",
    "    # You have to add the meshgrid according to this:\n",
    "    # https://discuss.pytorch.org/t/warp-video-frame-from-optical-flow/6013/4\n",
    "    W=norm_flow.size(1)\n",
    "    H=norm_flow.size(2)\n",
    "    \n",
    "    \"\"\"meshH, meshW= torch.meshgrid([torch.linspace(-1,1,W), torch.linspace(-1,1,H)])\n",
    "    print(\"flow shape\",norm_flow.shape, \"H\",H, \"W\",W)\n",
    "    print(\"mesh H shape\",meshH.shape)\n",
    "    print(\"norm flow shape\",norm_flow.shape)\"\"\"\n",
    "    \n",
    "    \n",
    "    yy = torch.arange(0, W).view(1,-1).repeat(H,1)\n",
    "    xx = torch.arange(0, H).view(-1,1).repeat(1,W)\n",
    "    xx = xx.view(1,1,H,W)\n",
    "    yy = yy.view(1,1,H,W)\n",
    "    grid = torch.cat((xx,yy),1).float().permute(0,3,2,1)\n",
    "       \n",
    "    norm_flow = norm_flow + grid\n",
    "    \n",
    "    \"\"\"norm_flow[:,:,:,0] = norm_flow[:,:,:,0] + meshW\n",
    "    norm_flow[:,:,:,1] = norm_flow[:,:,:,1] + meshH\"\"\"\n",
    "    \n",
    "    \n",
    "    norm_flow[:,:,:,0] = norm_flow[:,:,:,0] / (norm_flow.size(2)-1) # normalize it to (0,1)\n",
    "    norm_flow[:,:,:,1] = norm_flow[:,:,:,1] / (norm_flow.size(1)-1) # normalize it to (0,1)\n",
    "    \n",
    "    \n",
    "    norm_flow = norm_flow*2 - 1 # bringing it to the range (-1,1) for the grid_sample function\n",
    "    # interpolate the image with the flow\n",
    "    warped = tf.grid_sample(im, norm_flow)\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_warping_practice(im1, im2, flow_gt):\n",
    "    \"\"\" Visualizes the result of warping the second image by ground truth.\"\"\"\n",
    "    assert (im1.dim() == 4 and im2.dim() == 4 and flow_gt.dim() == 4)\n",
    "    assert (im1.size(1) in [1,3] and im2.size(1) in [1,3] and flow_gt.size(1) == 2)\n",
    "    \n",
    "    warped_im2 = warp_image(im2, flow_gt)\n",
    "    print(warped_im2.shape)\n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"Image 1\")\n",
    "    plt.imshow(im1[0,0,:,:], cmap=\"gray\")\n",
    "    plt.subplot(132)\n",
    "    plt.title(\"Warped Image 2\")\n",
    "    plt.imshow(warped_im2[0,0,:,:], cmap=\"gray\")\n",
    "    plt.subplot(133)\n",
    "    plt.title(\"Difference\")\n",
    "    plt.imshow(im1[0,0,:,:]-warped_im2[0,0,:,:], cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_hs(im1, im2, flow, lambda_hs):\n",
    "    \"\"\" Evalutes Horn-Schunck energy function.\"\"\"\n",
    "    assert (im1.dim() == 4 and im2.dim() == 4 and flow.dim() == 4)\n",
    "    assert (im1.size(1) == 1 and im2.size(1) == 1 and flow.size(1) == 2)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def grad_u(x,y): return np.gradient(flow[0,0,:,:])[x,y]\n",
    "    def grad_v(x,y): return np.gradient(flow[0,1,:,:])[x,y]\n",
    "    # TODO: Interpolate It1 and It0\n",
    "    def It1(x,y): return warp_image(im2,flow)[0,0,x,y]\n",
    "    def It0(x,y): return im1[0,0,x,y]\n",
    "\n",
    "    def integral(x,y):\n",
    "        return (It1(x,y)-It0(x,y))**2 + lambda_hs*(np.norm(grad_u)**2 + np.norm(grad_v)**2)\n",
    "    \n",
    "    energy = dblquad(integral, -np.inf, np.inf, -np.inf, np.inf)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using sum instead of integral (discrete pixels in picture)\n",
    "    It1 = warp_image(im2,flow)\n",
    "    It0 = im1\n",
    "    \n",
    "    # TODO: use sobelfilter on u(x,y) and v(x,y)\n",
    "    #sobel_filter = torch.tensor([[[[1., 2. , 1.], [0., 0., 0.], [-1., -2. , -1.]]]])\n",
    "    #f = sobel_filter.expand(1,1,3,3)\n",
    "    #grad_u = tf.conv2d(torch.unsqueeze(flow[0,0,:,:], 0), sobel_filter, padding=1)\n",
    "    #grad_v = tf.conv2d(torch.unsqueeze(flow[0,1,:,:], 0), sobel_filter, padding=1)\n",
    "    \n",
    "    #\n",
    "    \"\"\"u = torch.autograd.Variable(flow[:,0,:,:].unsqueeze(0))\n",
    "    v = torch.autograd.Variable(flow[:,1,:,:].unsqueeze(0))\"\"\"\n",
    "    \n",
    "    \n",
    "    #flipped sobels, die durch 4 haben wir von ner anderen gruppe. Bei Tabea funktioniert es nicht ohne\n",
    "    sobel_filter_x = torch.Tensor([[[[1., 0. , -1.], [2., 0., -2.], [1., 0. , -1.]]]])/4\n",
    "    sobel_filter_y = torch.Tensor([[[ [1., 2., 1.], [0., 0., 0.],[-1., -2., -1.]]]])/4\n",
    "    \n",
    "    \n",
    "    u = flow[:,0,:,:].unsqueeze(0)\n",
    "    v = flow[:,1,:,:].unsqueeze(0)\n",
    "\n",
    "    \n",
    "    du_dx = tf.conv2d(u, sobel_filter_x, padding=1)    \n",
    "    du_dy = tf.conv2d(u, sobel_filter_y, padding=1)                                         \n",
    "    dv_dx = tf.conv2d(v, sobel_filter_x, padding=1)\n",
    "    dv_dy = tf.conv2d(v, sobel_filter_y, padding=1)\n",
    "    \n",
    "    \n",
    "                                             \n",
    "    energy = torch.sum((It1-It0)**2) + torch.sum(lambda_hs*(du_dx**2+du_dy**2+(dv_dx**2+dv_dy**2)))\n",
    "    \n",
    "    \"\"\"for x in np.arange(0, np.shape(It1)[0]):\n",
    "        for y in np.arange(0, np.shape(It1)[1]):\n",
    "            energy += (It1[x,y]-It0[x,y])**2 \n",
    "            energy += lambda_hs*(norm([du_dx[0,0,x,y], du_dy[0,0,x,y]]) + norm([dv_dx[0,0,x,y], dv_dy[0,0,x,y]]))\"\"\"\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_flow(im1, im2, flow_gt, lambda_hs, learning_rate, num_iter):\n",
    "    \"\"\"\n",
    "    Estimate flow using HS with Gradient Descent.\n",
    "    Displays average endpoint error.\n",
    "    Visualizes flow field.\n",
    "\n",
    "    Returns estimated flow]\n",
    "    \"\"\"\n",
    "    assert (im1.dim() == 4 and im2.dim() == 4 and flow_gt.dim() == 4)\n",
    "    assert (im1.size(1) == 1 and im2.size(1) == 1 and flow_gt.size(1) == 2)\n",
    "\n",
    "    # Initial flow\n",
    "    flow = torch.rand(1,2,flow_gt.size(2),flow_gt.size(3),requires_grad=True)\n",
    "    \n",
    "    for i in np.arange(0, num_iter):\n",
    "        \n",
    "        # Forward pass\n",
    "        # TODO: Warp im1 or im2??\n",
    "        #Wenn dann bild 2 zu im1_estimate warpen, aber wir warpen doch schon in energy_hs\n",
    "        #im2_estimate = warp_image(im1,flow)\n",
    "        #loss = energy_hs(im1, im2_estimate, flow, lambda_hs)\n",
    "        \n",
    "        \n",
    "        loss = energy_hs(im1,im2,flow,lambda_hs)\n",
    "        \n",
    "        if not i%10: print(\"Iteration \", i+1, \"  Loss:\", loss)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        update = flow.grad\n",
    "        \n",
    "        #ist das hier nicht gradient ascent?\n",
    "        #flow += learning_rate * update\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            flow -= update * learning_rate \n",
    "        flow.grad.zero_()\n",
    "    \n",
    "    print(\"Gradient Descent AEPE: \", evaluate_flow(flow.data, flow_gt))\n",
    "    with torch.no_grad():\n",
    "        plt.figure()\n",
    "        plt.title(\"Flow estimated with gradient descent\")\n",
    "        plt.imshow(flow2rgb(torch2numpy(flow.data.resize(flow.size(1),flow.size(2),flow.size(3)))))\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_flow_LBFGS(im1, im2, flow_gt, lambda_hs, learning_rate, num_iter):\n",
    "    \"\"\"\n",
    "    Estimates flow using HS with LBFGS.\n",
    "    Displays average endpoint error.\n",
    "    Visualizes flow field.\n",
    "\n",
    "    Returns estimated flow\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initial flow\n",
    "    flo = torch.rand(1,2,im1.size(2),im1.size(3))\n",
    "    flo.requires_grad = True\n",
    "    \n",
    "    global c\n",
    "    c = 0\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(params=[flo], lr=learning_rate, max_iter=num_iter)\n",
    "\n",
    "    \n",
    "    def closure():\n",
    "        global c\n",
    "        c =  c + 1\n",
    "        optimizer.zero_grad()\n",
    "        #loss = energy_hs(im1,im2,flo,lambda_hs).clone().detach().requires_grad_(True)\n",
    "        loss = energy_hs(im1,im2,flo,lambda_hs)\n",
    "        if not c%50: print(\"Iteration: {} Loss: {}\".format(c, loss))\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    \n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    assert (im1.dim() == 4 and im2.dim() == 4 and flow_gt.dim() == 4)\n",
    "    assert (im1.size(1) == 1 and im2.size(1) == 1 and flow_gt.size(1) == 2)\n",
    "    \n",
    "    print(\"LBFGS AEPE: \", evaluate_flow(flo.data, flow_gt))\n",
    "    with torch.no_grad():\n",
    "        plt.figure()\n",
    "        plt.title(\"Flow estimated with LBFGS\")\n",
    "        plt.imshow(flow2rgb(torch2numpy(flo.data.resize(flo.size(1),flo.size(2),flo.size(3)))))\n",
    "        plt.show()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_flow_coarse_to_fine(im1, im2, flow_gt, lambda_hs, learning_rate,\n",
    "                                 num_iter, num_level):\n",
    "    \"\"\"\n",
    "    Estimates flow using HS with LBFGS in a coarse-to-fine scheme.\n",
    "    Displays average endpoint error.\n",
    "    Visualizes flow field.\n",
    "\n",
    "    Returns estimated flow\n",
    "    \"\"\"\n",
    "\n",
    "    # Initial flow\n",
    "    flo = torch.rand(1,2,int(im1.size(2)/num_level),int(im1.size(3)/num_level))\n",
    "    flo.requires_grad = True\n",
    "    \n",
    "    # Loop over levels\n",
    "    for l in np.arange(1, num_level+1):\n",
    "        print(\"Level {}:\".format(l))\n",
    "        sampling = torch.nn.Upsample(scale_factor=(l/num_level), mode='bilinear')\n",
    "        downsampled_im1 = sampling(im1)\n",
    "        downsampled_im2 = sampling(im2)\n",
    "        downsampled_flow_gt = sampling(flow_gt)\n",
    "        \n",
    "        print(\"Flo size: {} Downsampled GT size: {}\".format(flo.size(), downsampled_flow_gt.size()))\n",
    "\n",
    "        global c\n",
    "        c = 0\n",
    "        \n",
    "        optimizer = torch.optim.LBFGS(params=[flo], lr=learning_rate, max_iter=num_iter)\n",
    "        \n",
    "        def closure():\n",
    "            global c\n",
    "            c =  c + 1\n",
    "            optimizer.zero_grad()\n",
    "            loss = energy_hs(downsampled_im1, downsampled_im2,flo,lambda_hs)\n",
    "            # if not c%50: print(\"Iteration: {} Loss: {}\".format(c, loss))\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        \n",
    "        # Optimize flow for current level \n",
    "        optimizer.step(closure)\n",
    "        \n",
    "        print(\"LBFGS AEPE: \", evaluate_flow(flo.data, downsampled_flow_gt))\n",
    "        with torch.no_grad():\n",
    "            plt.figure()\n",
    "            plt.title(\"Flow estimated with LBFGS\")\n",
    "            plt.imshow(flow2rgb(torch2numpy(flo.data.resize(flo.size(1),flo.size(2),flo.size(3)))))\n",
    "            plt.show()\n",
    "        \n",
    "        flo_upsample_scaling_factor = ((l+1)/num_level)/(l/num_level)\n",
    "        print(\"Flo scaling factor: \", flo_upsample_scaling_factor)\n",
    "        sample = torch.nn.Upsample(scale_factor=flo_upsample_scaling_factor, mode='bilinear')\n",
    "        flo = variable(sample(flo).data, requires_grad=True)\n",
    "\n",
    "    assert (im1.dim() == 4 and im2.dim() == 4 and flow_gt.dim() == 4)\n",
    "    assert (im1.size(1) == 1 and im2.size(1) == 1 and flow_gt.size(1) == 2)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem2():\n",
    "    \n",
    "    \n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    # Loading data\n",
    "    #im1, im2, flow_gt = load_data(\"frame10.png\", \"frame11.png\", \"flow10.flo\")\n",
    "\n",
    "\n",
    "    # Parameters\n",
    "    lambda_hs = 0.0015\n",
    "    num_iter = 400\n",
    "\n",
    "    # Warping_practice\n",
    "    #visualize_warping_practice(im1, im2, flow_gt)\n",
    "    \n",
    "    #print(\"HS: \", energy_hs(im1,im2,flow_gt,lambda_hs))\n",
    "    \n",
    "    # Gradient descent\n",
    "    #learning_rate = 20.0\n",
    "    #learning_rate = 0.02\n",
    "    #estimate_flow(im1, im2, flow_gt, lambda_hs, learning_rate, num_iter)\n",
    "\n",
    "    # LBFGS\n",
    "    #learning_rate = 1.0\n",
    "    #estimate_flow_LBFGS(im1, im2, flow_gt, lambda_hs, learning_rate, num_iter)\n",
    "\n",
    "    # Coarse to fine\n",
    "    learning_rate = 1.0\n",
    "    num_level = 4\n",
    "    estimate_flow_coarse_to_fine(\n",
    "        im1, im2, flow_gt, lambda_hs, learning_rate, num_iter, num_level)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "problem2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
