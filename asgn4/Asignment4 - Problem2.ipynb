{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import color\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.nn import functional as tf\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from utils import VOC_LABEL2COLOR\n",
    "from utils import VOC_STATISTICS\n",
    "from utils import numpy2torch\n",
    "from utils import torch2numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOC Dataset class, derived from PyTorch Dataset\n",
    "class VOC2007Dataset(Dataset):\n",
    "    def __init__(self, root, train, num_examples):\n",
    "        super().__init__()\n",
    "        # Reading num_examples lines from the split file for the image names\n",
    "        if train:\n",
    "            split_file = open(root + \"/ImageSets/Segmentation/train.txt\", \"r\")\n",
    "        else:\n",
    "            split_file = open(root + \"/ImageSets/Segmentation/val.txt\", \"r\")\n",
    "        splits = []\n",
    "        # TODO: Read random line?\n",
    "        for _ in range(0, num_examples):\n",
    "            line = split_file.readline()\n",
    "            splits.append(line[:6])\n",
    "        split_file.close()\n",
    "        \n",
    "        # Reading pictures and gt for the entries in splits\n",
    "        self.images = np.array([])\n",
    "        self.labels = np.array([])\n",
    "        for name in splits:\n",
    "            im_file = open(root + \"/JPEGImages/{}.jpg\".format(name), \"r\")\n",
    "            #print(type(im_file.read()))\n",
    "            print(np.shape(im_file.read()))\n",
    "            # self.images.append(im_file.read())\n",
    "            gt_file = open(root + \"/SegmentationClass/{}.png\".format(name), \"r\")\n",
    "            # self.labels = ...\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        example_dict = dict()\n",
    "        assert (isinstance(example_dict, dict))\n",
    "        assert ('im' in example_dict.keys())\n",
    "        assert ('gt' in example_dict.keys())\n",
    "        return example_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        assert(self.images.size == self.labels.size)\n",
    "        return self.images.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and return pytorch.utils DataLoader\n",
    "def create_loader(dataset, batch_size, shuffle, num_workers):\n",
    "    loader = DataLoader(dataset, batch_size, shuffle, num_workers=num_workers)\n",
    "    assert (isinstance(loader, DataLoader))\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc_label2color(np_image, np_label):\n",
    "    assert (isinstance(np_image, np.ndarray))\n",
    "    assert (isinstance(np_label, np.ndarray))\n",
    "\n",
    "    colored = []\n",
    "\n",
    "    assert (np.equal(colored.shape, np_image.shape).all())\n",
    "    assert (np_image.dtype == colored.dtype)\n",
    "    return colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dataset_examples(loader, grid_height, grid_width, title):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_input(input_tensor):\n",
    "    normalized = []\n",
    "\n",
    "    assert (type(input_tensor) == type(normalized))\n",
    "    assert (input_tensor.size() == normalized.size())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_forward_pass(normalized, model):\n",
    "    prediction = []\n",
    "    acts = []\n",
    "\n",
    "    assert (isinstance(prediction, torch.Tensor))\n",
    "    assert (isinstance(acts, torch.Tensor))\n",
    "    return prediction, acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(prediction, gt):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_inference_examples(loader, model, grid_height, grid_width, title):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique_example(loader, unique_foreground_label):\n",
    "    example = []\n",
    "\n",
    "    assert (isinstance(example, dict))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_unique_example(example_dict, model):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_attack(example_dict, model, src_label, target_label, learning_rate, iterations):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem2():\n",
    "    # Please set an environment variables 'VOC2007_HOME' pointing to your '../VOCdevkit/VOC2007' folder\n",
    "    os.environ[\"VOC2007_HOME\"] = \"/home/yannik/Computer-Vison-2/asgn4/VOCdevkit/VOC2007\"\n",
    "    root = os.environ[\"VOC2007_HOME\"]\n",
    "\n",
    "    \n",
    "    # create datasets for training and validation\n",
    "    #train_dataset = VOC2007Dataset(root, train=True, num_examples=128)\n",
    "    train_dataset = VOC2007Dataset(root, train=True, num_examples=2)\n",
    "    #valid_dataset = VOC2007Dataset(root, train=False, num_examples=128)\n",
    "    valid_dataset = VOC2007Dataset(root, train=False, num_examples=2)\n",
    "    \n",
    "    # create data loaders for training and validation\n",
    "    # you can safely assume batch_size=1 in our tests..\n",
    "    train_loader = create_loader(train_dataset, batch_size=1, shuffle=True, num_workers=1)\n",
    "    valid_loader = create_loader(valid_dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "    \"\"\"\n",
    "    # show some images for the training and validation set\n",
    "    show_dataset_examples(train_loader, grid_height=2, grid_width=3, title='training examples')\n",
    "    show_dataset_examples(valid_loader, grid_height=2, grid_width=3, title='validation examples')\n",
    "\n",
    "    # Load Deeplab network\n",
    "    model = models.segmentation.deeplabv3_resnet101(pretrained=True, num_classes=21)\n",
    "\n",
    "    # Apply deeplab. Switch to training loader if you want more variety.\n",
    "    show_inference_examples(valid_loader, model, grid_height=2, grid_width=3, title='inference examples')\n",
    "\n",
    "    # attack1: convert cat to dog\n",
    "    cat_example = find_unique_example(valid_loader, unique_foreground_label=8)\n",
    "    show_unique_example(cat_example, model=model)\n",
    "    show_attack(cat_example, model, src_label=8, target_label=12, learning_rate=1.0, iterations=10)\n",
    "    \"\"\"\n",
    "    \n",
    "    # feel free to try other examples.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-a0d56136345e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mproblem2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-155-935c04059540>\u001b[0m in \u001b[0;36mproblem2\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# create datasets for training and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#train_dataset = VOC2007Dataset(root, train=True, num_examples=128)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVOC2007Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#valid_dataset = VOC2007Dataset(root, train=False, num_examples=128)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mvalid_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVOC2007Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-144-8aafbf1dd176>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, num_examples)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mim_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/JPEGImages/{}.jpg\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m#print(type(im_file.read()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;31m# self.images.append(im_file.read())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mgt_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/SegmentationClass/{}.png\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    problem2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
